{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "import json\n",
    "from spacy.pipeline import EntityRuler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text_image(image_file):\n",
    "    # Load the input image\n",
    "    image = cv2.imread(image_file)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Binarization\n",
    "    thresh, im_bw = cv2.threshold(gray_image, 210, 230, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Noise Removal\n",
    "    def noise_removal(image):\n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        image = cv2.dilate(image, kernel, iterations=1)  # Dilate the image to remove noise \n",
    "        kernel = np.ones((1, 1), np.uint8)\n",
    "        image = cv2.erode(image, kernel, iterations=1)\n",
    "        image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "        image = cv2.medianBlur(image, 3)\n",
    "        return image\n",
    "\n",
    "    no_noise = noise_removal(im_bw)\n",
    "\n",
    "    # Perform text extraction using Tesseract OCR\n",
    "    extracted_text = pytesseract.image_to_string(no_noise)\n",
    "\n",
    "\n",
    "    # Save the preprocessed image\n",
    "    cv2.imwrite(\"preprocessed_image.jpg\", no_noise)\n",
    "\n",
    "    # Save the extracted text to a text file\n",
    "    with open(\"extracted_text.txt\", \"w\") as text_file:\n",
    "        text_file.write(extracted_text)\n",
    "    \n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lettre de Motivation Simple\n",
      "\n",
      "Pherre Letetrere\n",
      "2A rue du Cet\n",
      "45000 Oridans\n",
      "06 06 06 06 06\n",
      "pierre lafebvre@pnad.com\n",
      "\n",
      "[NOM DE LENTREPRISE;\n",
      "[ADRESSE DL VEN TREPRISE;\n",
      "\n",
      "A{UEU), le (OATE)\n",
      "Objet : Concidature ou poste de [nom du poste suquel tu pottules]\n",
      "\n",
      "Madame, Monseut,\n",
      "\n",
      "Par % buns te La presente e€ du CV c-jomnt, je Lounaite airs soumatte mon profil et\n",
      "Yous expamer toute ma motryaton pour exercer les fonct-ons de [empha pour ‘quel tu\n",
      "postules - réf | av semn de votre service de [sence pow kequei ty postules])\n",
      "\n",
      " \n",
      "\n",
      "Lots de mes derneres expénences protessonne'les, fa travalié pour difterentes\n",
      "entropies du secteur jsecteur ov secteurs dans Iesquets tu as trawalé), Co fai pu acquére\n",
      "#t céveloppar de sobdes connassances en [mantionne les programmes ou .e comanes,\n",
      "dans lesquets tu a3 acquis des connassances]. entre autres, que yaimerars partager avec\n",
      "vous et continurr & approfondy au se:n Tune équipe dyuamaue et suinutante.\n",
      "\n",
      " \n",
      "\n",
      "‘Au cours de ma cerdre expérence professionnelle a/cher (Gernuere entreprise das\n",
      "fequele ty as travelle] sm exalement cu Youeson de contnbuer au developement de\n",
      "atttérents prowts, raison pour laquele le fat ce continues & travailer au lancement de\n",
      "nouvelles Kiécs el o'apprendre aux cOtes d'une nouve te dauipe me motrve énor nement,\n",
      "\n",
      " \n",
      "\n",
      "Je sara cave) 08 vous rencontre: 2 “Avenir pow pouvalr parler de votre entrepnse et\n",
      "dela mason proposée.\n",
      "\n",
      "En vous remerciant pour le temps que vous aurer bien voulu accorder 8 ma lettre, je\n",
      "vous pre de bien voulow agréer, madame, monweut, mes plus cordisles sahitations,\n",
      "\n",
      "ISOM, PRENOM ET SIGNATURE!\n",
      "\n",
      "Modeles4¢ Cv\n",
      "\n",
      "wan reek de Oy eam\n",
      "\n",
      " \n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_file = '01.jpg'\n",
    "extracted_text= preprocess_text_image(image_file)\n",
    "print(extracted_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Load the spaCy French model\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "    \n",
    "    # Define custom patterns for named entities\n",
    "    custom_patterns = [\n",
    "        {\"label\": \"PERSON\", \"pattern\": [{\"LOWER\": {\"IN\": [\"mr.\", \"mrs.\", \"ms.\", \"dr.\", \"prof.\"]}}, {\"IS_ALPHA\": True, \"IS_TITLE\": True}]},\n",
    "        {\"label\": \"ORG\", \"pattern\": [{\"TEXT\": {\"REGEX\": \"^(inc|llc|ltd|corp|s\\\\.?a\\\\.?|s\\\\.p\\\\.a|s\\\\.r\\\\.l|s\\\\.c\\\\.a)$\"}}]}\n",
    "        # Add more custom patterns for other entities as needed\n",
    "    ]\n",
    "    \n",
    "    # Add custom patterns to the entity ruler\n",
    "    ruler = EntityRuler(nlp)\n",
    "    for pattern in custom_patterns:\n",
    "        ruler.add_patterns([pattern])\n",
    "    nlp.add_pipe(ruler)\n",
    "\n",
    "    # Analyze the text using spaCy\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Extract named entities\n",
    "    named_entities = [{'text': ent.text, 'label': ent.label_} for ent in doc.ents]\n",
    "    \n",
    "    # Perform spell checking for French text\n",
    "    spell = SpellChecker(language='fr')\n",
    "    corrected_text_tokens = []\n",
    "    for word in text.split():\n",
    "        correction = spell.correction(word)\n",
    "        corrected_text_tokens.append(correction if correction is not None else word)\n",
    "    corrected_text = ' '.join(corrected_text_tokens)\n",
    "    \n",
    "    # Structure the information into JSON\n",
    "    output = {\n",
    "        'original_text': text,\n",
    "        'corrected_text': corrected_text,\n",
    "        'named_entities': named_entities\n",
    "    }\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.entityruler.EntityRuler object at 0x75ad6700f580> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save the processed data to a JSON file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocessed_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n",
      "Cell \u001b[0;32mIn[15], line 16\u001b[0m, in \u001b[0;36mprocess_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m custom_patterns:\n\u001b[1;32m     15\u001b[0m     ruler\u001b[38;5;241m.\u001b[39madd_patterns([pattern])\n\u001b[0;32m---> 16\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_pipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Analyze the text using spaCy\u001b[39;00m\n\u001b[1;32m     19\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(text)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/spacy/language.py:807\u001b[0m, in \u001b[0;36mLanguage.add_pipe\u001b[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001b[0m\n\u001b[1;32m    805\u001b[0m     bad_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrepr\u001b[39m(factory_name)\n\u001b[1;32m    806\u001b[0m     err \u001b[38;5;241m=\u001b[39m Errors\u001b[38;5;241m.\u001b[39mE966\u001b[38;5;241m.\u001b[39mformat(component\u001b[38;5;241m=\u001b[39mbad_val, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    808\u001b[0m name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m factory_name\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent_names:\n",
      "\u001b[0;31mValueError\u001b[0m: [E966] `nlp.add_pipe` now takes the string name of the registered component factory, not a callable component. Expected string, but got <spacy.pipeline.entityruler.EntityRuler object at 0x75ad6700f580> (name: 'None').\n\n- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and call `nlp.add_pipe('name')` instead.\n\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string name instead, e.g. `nlp.add_pipe('textcat')`.\n\n- If you're using a custom component: Add the decorator `@Language.component` (for function components) or `@Language.factory` (for class components / factories) to your custom component and assign it a name, e.g. `@Language.component('your_name')`. You can then run `nlp.add_pipe('your_name')` to add it to the pipeline."
     ]
    }
   ],
   "source": [
    "processed_data = process_text(extracted_text)\n",
    "\n",
    "# Save the processed data to a JSON file\n",
    "with open('processed_data.json', 'w') as json_file:\n",
    "    json.dump(processed_data, json_file, indent=4)\n",
    "\n",
    "print(\"Processed data saved to processed_data.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
